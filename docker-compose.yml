version: '3.8'

services:
  baseline-agent-cli:
    build:
      context: ./baseline-agent-cli
      dockerfile: Dockerfile
    ports:
      - "8081:8080"
    environment:
      - CHUTES_API_KEY=${CHUTES_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://llm.chutes.ai/v1}
      - BASELINE_AGENT_CLI_MODEL=${BASELINE_AGENT_CLI_MODEL:-unsloth/Llama-3.2-1B-Instruct}
      - SANDY_BASE_URL=${SANDY_BASE_URL:-https://sandy.chutes.ai}
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  baseline-langchain:
    build:
      context: ./baseline-langchain
      dockerfile: Dockerfile
    ports:
      - "8082:8080"
    environment:
      - CHUTES_API_KEY=${CHUTES_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://llm.chutes.ai/v1}
      - BASELINE_LANGCHAIN_MODEL=${BASELINE_LANGCHAIN_MODEL:-Qwen/Qwen3-14B}
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # Gateway for testing the full flow
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - COMPETITOR_URL=http://baseline-agent-cli:8080
      - DEBUG=true
    depends_on:
      - baseline-agent-cli
    restart: unless-stopped
